{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051816a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the complaints file using the existing data_path variable\n",
    "\n",
    "data_path = 'supplementary/complaitns_for_anger.csv' # change this to the correct path\n",
    "complaints = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the file\n",
    "complaints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af19e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complaints.xlsx has been successfully converted to Complaints.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert the Excel file to a CSV file\n",
    "# complaints.to_csv('Complaints.csv', index=False)\n",
    "\n",
    "# print(\"Complaints.xlsx has been successfully converted to Complaints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37b3ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model TinyLlama/TinyLlama-1.1B-Chat-v1.0 on cpu...\n",
      "Processing batch 1, complaints 1-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oldys\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, complaints 9-16\n",
      "Processing batch 3, complaints 17-24\n",
      "Processing batch 4, complaints 25-32\n",
      "Processing batch 5, complaints 33-40\n",
      "Processing batch 6, complaints 41-48\n",
      "Processing batch 7, complaints 49-56\n",
      "Processing batch 8, complaints 57-64\n",
      "Processing batch 9, complaints 65-72\n",
      "Processing batch 10, complaints 73-80\n",
      "Processing batch 11, complaints 81-88\n",
      "Processing batch 12, complaints 89-96\n",
      "Processing batch 13, complaints 97-104\n",
      "Processing batch 14, complaints 105-112\n",
      "Processing batch 15, complaints 113-120\n",
      "Processing batch 16, complaints 121-128\n",
      "Processing batch 17, complaints 129-136\n",
      "Processing batch 18, complaints 137-144\n",
      "Processing batch 19, complaints 145-152\n",
      "Processing batch 20, complaints 153-160\n",
      "Processing batch 21, complaints 161-168\n",
      "Processing batch 22, complaints 169-176\n",
      "Processing batch 23, complaints 177-184\n",
      "Processing batch 24, complaints 185-192\n",
      "Processing batch 25, complaints 193-200\n",
      "Processing batch 26, complaints 201-208\n",
      "Processing batch 27, complaints 209-216\n",
      "Processing batch 28, complaints 217-224\n",
      "Processing batch 29, complaints 225-232\n",
      "Processing batch 30, complaints 233-240\n",
      "Processing batch 31, complaints 241-248\n",
      "Processing batch 32, complaints 249-256\n",
      "Processing batch 33, complaints 257-264\n",
      "Processing batch 34, complaints 265-272\n",
      "Processing batch 35, complaints 273-280\n",
      "Processing batch 36, complaints 281-288\n",
      "Processing batch 37, complaints 289-296\n",
      "Processing batch 38, complaints 297-304\n",
      "Processing batch 39, complaints 305-312\n",
      "Processing batch 40, complaints 313-320\n",
      "Processing batch 41, complaints 321-328\n",
      "Processing batch 42, complaints 329-336\n",
      "Processing batch 43, complaints 337-344\n",
      "Processing batch 44, complaints 345-352\n",
      "Processing batch 45, complaints 353-360\n",
      "Processing batch 46, complaints 361-368\n",
      "Processing batch 47, complaints 369-376\n",
      "Processing batch 48, complaints 377-384\n",
      "Processing batch 49, complaints 385-392\n",
      "Processing batch 50, complaints 393-400\n",
      "Processing batch 51, complaints 401-408\n",
      "Processing batch 52, complaints 409-416\n",
      "Processing batch 53, complaints 417-424\n",
      "Processing batch 54, complaints 425-432\n",
      "Processing batch 55, complaints 433-440\n",
      "Processing batch 56, complaints 441-448\n",
      "Processing batch 57, complaints 449-456\n",
      "Processing batch 58, complaints 457-464\n",
      "Processing batch 59, complaints 465-472\n",
      "Processing batch 60, complaints 473-480\n",
      "Processing batch 61, complaints 481-488\n",
      "Processing batch 62, complaints 489-496\n",
      "Processing batch 63, complaints 497-504\n",
      "Processing batch 64, complaints 505-512\n",
      "Processing batch 65, complaints 513-520\n",
      "Processing batch 66, complaints 521-528\n",
      "Processing batch 67, complaints 529-536\n",
      "Processing batch 68, complaints 537-544\n",
      "Processing batch 69, complaints 545-552\n",
      "Processing batch 70, complaints 553-560\n",
      "Processing batch 71, complaints 561-568\n",
      "Processing batch 72, complaints 569-576\n",
      "Processing batch 73, complaints 577-584\n",
      "Processing batch 74, complaints 585-592\n",
      "Processing batch 75, complaints 593-600\n",
      "Processing batch 76, complaints 601-608\n",
      "Processing batch 77, complaints 609-616\n",
      "Processing batch 78, complaints 617-624\n",
      "Processing batch 79, complaints 625-632\n",
      "Processing batch 80, complaints 633-640\n",
      "Processing batch 81, complaints 641-648\n",
      "Processing batch 82, complaints 649-656\n",
      "Processing batch 83, complaints 657-664\n",
      "Processing batch 84, complaints 665-672\n",
      "Processing batch 85, complaints 673-680\n",
      "Processing batch 86, complaints 681-688\n",
      "Processing batch 87, complaints 689-696\n",
      "Processing batch 88, complaints 697-704\n",
      "Processing batch 89, complaints 705-712\n",
      "Processing batch 90, complaints 713-720\n",
      "Processing batch 91, complaints 721-728\n",
      "Processing batch 92, complaints 729-736\n",
      "Processing batch 93, complaints 737-744\n",
      "Processing batch 94, complaints 745-752\n",
      "Processing batch 95, complaints 753-760\n",
      "Processing batch 96, complaints 761-768\n",
      "Processing batch 97, complaints 769-776\n",
      "Processing batch 98, complaints 777-784\n",
      "Processing batch 99, complaints 785-792\n",
      "Processing batch 100, complaints 793-800\n",
      "Processing batch 101, complaints 801-808\n",
      "Processing batch 102, complaints 809-816\n",
      "Processing batch 103, complaints 817-824\n",
      "Processing batch 104, complaints 825-832\n",
      "Processing batch 105, complaints 833-840\n",
      "Processing batch 106, complaints 841-848\n",
      "Processing batch 107, complaints 849-856\n",
      "Processing batch 108, complaints 857-864\n",
      "Processing batch 109, complaints 865-872\n",
      "Processing batch 110, complaints 873-880\n",
      "Processing batch 111, complaints 881-888\n",
      "Processing batch 112, complaints 889-896\n",
      "Processing batch 113, complaints 897-904\n",
      "Processing batch 114, complaints 905-912\n",
      "Processing batch 115, complaints 913-920\n",
      "Processing batch 116, complaints 921-928\n",
      "Processing batch 117, complaints 929-936\n",
      "Processing batch 118, complaints 937-944\n",
      "Processing batch 119, complaints 945-952\n",
      "Processing batch 120, complaints 953-960\n",
      "Processing batch 121, complaints 961-968\n",
      "Processing batch 122, complaints 969-976\n",
      "Processing batch 123, complaints 977-984\n",
      "Processing batch 124, complaints 985-992\n",
      "Processing batch 125, complaints 993-1000\n",
      "Processing batch 126, complaints 1001-1008\n",
      "Processing batch 127, complaints 1009-1016\n",
      "Processing batch 128, complaints 1017-1024\n",
      "Processing batch 129, complaints 1025-1032\n",
      "Processing batch 130, complaints 1033-1040\n",
      "Processing batch 131, complaints 1041-1048\n",
      "Processing batch 132, complaints 1049-1056\n",
      "Processing batch 133, complaints 1057-1064\n",
      "Processing batch 134, complaints 1065-1072\n",
      "Processing batch 135, complaints 1073-1080\n",
      "Processing batch 136, complaints 1081-1088\n",
      "Processing batch 137, complaints 1089-1096\n",
      "Processing batch 138, complaints 1097-1104\n",
      "Processing batch 139, complaints 1105-1112\n",
      "Processing batch 140, complaints 1113-1120\n",
      "Processing batch 141, complaints 1121-1128\n",
      "Processing batch 142, complaints 1129-1136\n",
      "Processing batch 143, complaints 1137-1144\n",
      "Processing batch 144, complaints 1145-1152\n",
      "Processing batch 145, complaints 1153-1160\n",
      "Processing batch 146, complaints 1161-1168\n",
      "Processing batch 147, complaints 1169-1176\n",
      "Processing batch 148, complaints 1177-1184\n",
      "Processing batch 149, complaints 1185-1192\n",
      "Processing batch 150, complaints 1193-1200\n",
      "Processing batch 151, complaints 1201-1208\n",
      "Processing batch 152, complaints 1209-1216\n",
      "Processing batch 153, complaints 1217-1224\n",
      "Processing batch 154, complaints 1225-1232\n",
      "Processing batch 155, complaints 1233-1240\n",
      "Processing batch 156, complaints 1241-1248\n",
      "Processing batch 157, complaints 1249-1256\n",
      "Processing batch 158, complaints 1257-1264\n",
      "Processing batch 159, complaints 1265-1272\n",
      "Processing batch 160, complaints 1273-1280\n",
      "Processing batch 161, complaints 1281-1288\n",
      "Processing batch 162, complaints 1289-1296\n",
      "Processing batch 163, complaints 1297-1304\n",
      "Processing batch 164, complaints 1305-1312\n",
      "Processing batch 165, complaints 1313-1320\n",
      "Processing batch 166, complaints 1321-1328\n",
      "Processing batch 167, complaints 1329-1336\n",
      "Processing batch 168, complaints 1337-1344\n",
      "Processing batch 169, complaints 1345-1352\n",
      "Processing batch 170, complaints 1353-1360\n",
      "Processing batch 171, complaints 1361-1368\n",
      "Processing batch 172, complaints 1369-1376\n",
      "Processing batch 173, complaints 1377-1384\n",
      "Processing batch 174, complaints 1385-1392\n",
      "Processing batch 175, complaints 1393-1400\n",
      "Processing batch 176, complaints 1401-1408\n",
      "Processing batch 177, complaints 1409-1416\n",
      "Processing batch 178, complaints 1417-1424\n",
      "Processing batch 179, complaints 1425-1432\n",
      "Processing batch 180, complaints 1433-1440\n",
      "Processing batch 181, complaints 1441-1448\n",
      "Processing batch 182, complaints 1449-1456\n",
      "Processing batch 183, complaints 1457-1464\n",
      "Processing batch 184, complaints 1465-1472\n",
      "Processing batch 185, complaints 1473-1480\n",
      "Processing batch 186, complaints 1481-1488\n",
      "Processing batch 187, complaints 1489-1496\n",
      "Processing batch 188, complaints 1497-1504\n",
      "Processing batch 189, complaints 1505-1512\n",
      "Processing batch 190, complaints 1513-1520\n",
      "Processing batch 191, complaints 1521-1528\n",
      "Processing batch 192, complaints 1529-1536\n",
      "Processing batch 193, complaints 1537-1544\n",
      "Processing batch 194, complaints 1545-1552\n",
      "Processing batch 195, complaints 1553-1560\n",
      "Processing batch 196, complaints 1561-1568\n",
      "Processing batch 197, complaints 1569-1576\n",
      "Processing batch 198, complaints 1577-1584\n",
      "Processing batch 199, complaints 1585-1592\n",
      "Processing batch 200, complaints 1593-1600\n",
      "Processing batch 201, complaints 1601-1605\n",
      "Saved results to Complaints_with_anger_scores.csv\n",
      "\n",
      "Summary of Anger Scores:\n",
      "Average Anger Score: 5.52\n",
      "Median Anger Score: 5.00\n",
      "Most Angry Complaint Score: 10.00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def setup_local_model(model_name=\"deepseek-ai/deepseek-coder-1.3b-base\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Load a smaller DeepSeek model locally.\n",
    "    Falls back to CPU if CUDA is not available.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available, otherwise use CPU\n",
    "    if device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"CUDA not available, switching to CPU\")\n",
    "        device = \"cpu\"\n",
    "    \n",
    "    print(f\"Loading model {model_name} on {device}...\")\n",
    "    \n",
    "    # Loading in 4-bit quantization to reduce memory usage\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # For 4-bit quantization (requires bitsandbytes library)\n",
    "        if device == \"cuda\":\n",
    "            try:\n",
    "                # Attempt to load with 4-bit quantization\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    load_in_4bit=True,\n",
    "                    device_map=\"auto\"\n",
    "                )\n",
    "                print(\"Model loaded with 4-bit quantization\")\n",
    "            except Exception as e:\n",
    "                print(f\"4-bit quantization failed: {e}\")\n",
    "                # Fall back to regular loading\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    device_map=\"auto\"\n",
    "                )\n",
    "        else:\n",
    "            # CPU loading (no quantization)\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "            model.to(device)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Trying alternative smaller model...\")\n",
    "        \n",
    "        # Fallback to an even smaller model\n",
    "        fallback_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(fallback_model)\n",
    "        model = AutoModelForCausalLM.from_pretrained(fallback_model)\n",
    "        model.to(device)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def get_anger_score_local(complaint_text, model, tokenizer, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Get anger score using a locally deployed model\n",
    "    \"\"\"\n",
    "    # Create prompt for anger score analysis\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following customer complaint and rate it on an anger/frustration scale from 0 to 10, \n",
    "    where 0 is completely neutral/calm and 10 is extremely angry/frustrated.\n",
    "    \n",
    "    Only respond with a number between 0 and 10.\n",
    "    \n",
    "    Customer Complaint: {complaint_text}\n",
    "    \n",
    "    Anger Score:\"\"\"\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate a response with the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=5,\n",
    "            temperature=0.1,\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    # Decode the generated response\n",
    "    response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Extract anger score from response\n",
    "    try:\n",
    "        # Try to find a number in the response\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', response)\n",
    "        if numbers:\n",
    "            score = float(numbers[0])\n",
    "            # Clamp to 0-10 range\n",
    "            score = max(0, min(10, score))\n",
    "            return score\n",
    "        else:\n",
    "            print(f\"Could not extract a number from response: '{response}'\")\n",
    "            return 5.0  # Default neutral score\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting anger score: {e}\")\n",
    "        return 5.0  # Default neutral score\n",
    "\n",
    "def process_complaints_dataset_local(csv_path, model_name=\"deepseek-ai/deepseek-coder-1.3b-base\"):\n",
    "    \"\"\"\n",
    "    Process a CSV file containing complaints and add anger scores using a local model\n",
    "    \"\"\"\n",
    "    # Determine device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Setup model\n",
    "    model, tokenizer = setup_local_model(model_name, device)\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Create a new column for anger scores\n",
    "    df['anger_score'] = None\n",
    "    \n",
    "    # Process each complaint\n",
    "    total = len(df)\n",
    "    for index, row in df.iterrows():\n",
    "        complaint_text = row['complaint']  # Adjust column name as needed\n",
    "        \n",
    "        # Get anger score\n",
    "        anger_score = get_anger_score_local(complaint_text, model, tokenizer, device)\n",
    "        \n",
    "        # Update dataframe\n",
    "        df.at[index, 'anger_score'] = anger_score\n",
    "        \n",
    "        # Print progress\n",
    "        if index % 5 == 0 or index == total - 1:\n",
    "            print(f\"Processed {index+1}/{total} complaints ({(index+1)/total*100:.1f}%)\")\n",
    "    \n",
    "    # Save the updated dataset\n",
    "    output_path = csv_path.replace('.csv', '_with_anger_scores.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example with batched processing for faster inference\n",
    "def process_complaints_in_batches(csv_path, model_name=\"deepseek-ai/deepseek-coder-1.3b-base\", batch_size=8):\n",
    "    \"\"\"\n",
    "    Process complaints in batches for faster inference\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, tokenizer = setup_local_model(model_name, device)\n",
    "    \n",
    "    # Load dataset\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Create anger score column\n",
    "    df['anger_score'] = None\n",
    "    \n",
    "    # Process in batches\n",
    "    total_complaints = len(df)\n",
    "    for i in range(0, total_complaints, batch_size):\n",
    "        batch_end = min(i + batch_size, total_complaints)\n",
    "        batch = df.iloc[i:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {i//batch_size + 1}, complaints {i+1}-{batch_end}\")\n",
    "        \n",
    "        # Process each complaint in the batch\n",
    "        for idx, row in batch.iterrows():\n",
    "            complaint_text = row['complaint']  # Adjust column name\n",
    "            anger_score = get_anger_score_local(complaint_text, model, tokenizer, device)\n",
    "            df.at[idx, 'anger_score'] = anger_score\n",
    "    \n",
    "    # Save results\n",
    "    output_path = csv_path.replace('.csv', '_with_anger_scores.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify your dataset path\n",
    "    complaints_dataset_path = \"Complaints.csv\"\n",
    "    \n",
    "    # For a smaller model, use one of these options:\n",
    "    # model_options = [\n",
    "    #     \"deepseek-ai/deepseek-coder-1.3b-base\",  # 1.3B parameters\n",
    "    #     \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",    # 1.1B parameters\n",
    "    #     \"microsoft/phi-2\",                        # 2.7B parameters\n",
    "    # ]\n",
    "    \n",
    "    # Process with batching for better performance\n",
    "    results_df = process_complaints_in_batches(\n",
    "        complaints_dataset_path,\n",
    "        model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # Choose a smaller model\n",
    "        batch_size=8  # Adjust based on your GPU memory\n",
    "    )\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary of Anger Scores:\")\n",
    "    print(f\"Average Anger Score: {results_df['anger_score'].mean():.2f}\")\n",
    "    print(f\"Median Anger Score: {results_df['anger_score'].median():.2f}\")\n",
    "    print(f\"Most Angry Complaint Score: {results_df['anger_score'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a166d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results_df as complaints_angry_scores.csv with only customerID and anger_score columns\n",
    "results_df[['customerID', 'anger_score']].to_csv('complaints_angry_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b3d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger_score\n",
      "5.0    1196\n",
      "6.0     196\n",
      "7.0       1\n",
      "8.0     206\n",
      "9.0       4\n",
      "10        2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## Show distribution of anger scores\n",
    "print(results_df.anger_score.value_counts().sort_index())\n",
    "\n",
    "results_df.anger_score.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger_score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>The DSL internet service has been inconsistent lately, with frequent slowdowns during peak hours. This is making it difficult for my family to complete their tasks online.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>The internet service has been very inconsistent, with frequent outages and slow speeds, making it difficult to complete important tasks. This has been an ongoing issue despite being a loyal customer for 34 months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>I have been charged a high monthly fee of $79.70, but the quality of service, particularly the streaming and internet speed, does not match the cost. It feels like I am overpaying for subpar services.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>The streaming TV service frequently buffers or crashes, making it impossible for me to watch anything without interruptions. This has been ongoing despite my high monthly charges, and I am very frustrated with the lack of reliability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>I am extremely dissatisfied with the internet service. Despite paying consistently for 16 months, the connection has been slow and unreliable, and no meaningful assistance has been provided to resolve these issues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>I have no access to any additional security features like OnlineSecurity, which makes me concerned about the safety of my connection. Why is this not offered or at least suggested as an option?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                              complaint\n",
       "anger_score                                                                                                                                                                                                                                            \n",
       "5.0                                                                         The DSL internet service has been inconsistent lately, with frequent slowdowns during peak hours. This is making it difficult for my family to complete their tasks online.\n",
       "6.0                               The internet service has been very inconsistent, with frequent outages and slow speeds, making it difficult to complete important tasks. This has been an ongoing issue despite being a loyal customer for 34 months.\n",
       "7.0                                            I have been charged a high monthly fee of $79.70, but the quality of service, particularly the streaming and internet speed, does not match the cost. It feels like I am overpaying for subpar services.\n",
       "8.0          The streaming TV service frequently buffers or crashes, making it impossible for me to watch anything without interruptions. This has been ongoing despite my high monthly charges, and I am very frustrated with the lack of reliability.\n",
       "9.0                              I am extremely dissatisfied with the internet service. Despite paying consistently for 16 months, the connection has been slow and unreliable, and no meaningful assistance has been provided to resolve these issues.\n",
       "10.0                                                  I have no access to any additional security features like OnlineSecurity, which makes me concerned about the safety of my connection. Why is this not offered or at least suggested as an option?"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Show the examples of complaints with different anger scores\n",
    "\n",
    "# Adjust pandas display options to prevent clipping of long text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Group by anger_score and display one example complaint for each score\n",
    "examples = results_df.groupby('anger_score').first()[['complaint']]\n",
    "examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
